[
["index.html", "STAT 394: Causal Inference Welcome!", " STAT 394: Causal Inference Welcome! Image source: IMDB. (Know how this relates to class? Tell the instructor!) This is the course website for STAT 394: Causal Inference at Macalester College for the Spring 2020 semester. The content here was made by Leslie Myint and draws upon several resources, all of which are listed on the References page. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],
["references.html", "References", " References The material for this course draws from the following list of excellent resources. Required references (download these!): Causal Inference in Statistics: A Primer, by Judea Pearl, Madelyn Glymour, and Nicholas P. Jewell. PDF freely available online. (Referred to as “PRIMER”.) Causal Inference: What If, by Miguel A. Hernán and James M. Robins. PDF freely available online. (Referred to as “WHATIF”.) Other materials: The Book of Why: The New Science of Cause and Effect, by Judea Pearl and Dana Mackenzie (Amazon) Causality: Models, Reasoning, and Inference, by Judea Pearl (available as an eBook through Macalester’s libarary) Materials from the course, Causal Inference in Medicine and Public Health, taught by Elizabeth Stuart at JHSPH edX course: Causal Diagrams: Draw Your Assumptions Before Your Conclusions Udemy course: Causal Data Science with Directed Acyclic Graphs "],
["schedule.html", "Schedule", " Schedule Week 1 Thursday, January 23 Introductions, review of key ideas from STAT 155, why we need causal stories (graphs!) Slides from class are available here. After class: Recommended reading: PRIMER, Chapter 1: Sections 1.1, 1.2 Required reading: PRIMER, Chapter 1: 1.4, 1.5.1 Week 2 Thursday, January 30 The mathematics (probability) of graphs Before class: Please watch the following two videos and/or read the corresponding sections of PRIMER. Answer the Moodle questions before class. Video 1: Essentials of Probability, (slides) Video 2: Key Structure in DAGs, (slides) Reading: PRIMER, Chapter 1: Sections 1.3.1 to 1.3.5, Chapter 2: Sections 2.1 to 2.3 Week 3 Tuesday, February 4 d-separation and its applications for understanding bias Before class: Reading: PRIMER, Chapter 2: Section 2.4. There is one associated Moodle question for this reading. Please also read the article The Birth Weight “Paradox” Uncovered? available in the Readings section on Moodle. We will discuss in class on Tuesday. Tuesday, February 4 d-separation and its applications for understanding bias (continued) No new reading. Work on Homework 1, due Thursday, February 13 in class. Week 4 Tuesday, February 11 The do-operator and estimating causal effects Before class: Required reading: PRIMER, Chapter 1: 1.3.6 and 1.3.7, Chapter 3: Sections 3.1 through 3.3 (skip 3.2.2 on Multiple Interventions). Answer the Moodle questions (under “The do-operator and estimating causal effects”) before class. Thursday, February 13 The do-operator and estimating causal effects (continued) Week 5 Tuesday, February 18 The do-operator and estimating causal effects (continued) Thursday, February 20 Inverse probability weighting and structural models Before class: Required reading: WHATIF Sections 1.1 to 1.3 (Chapter 1: A definition of causal effect) and Chapter 12: IP weighting and marginal structural models. No Moodle questions this week. Just read to familiarize yourselves with the ideas, which we’ll discuss in class this week. Chapter 12 is a little more technical - let the following questions guide your reading: What is the concept of the “pseudo-population”? What is the nice characteristic that it has? How does IP weighting achieve that characteristic? How are stabilized IP weights different from ordinary (unstabilized) weights? Why would we want to use stabilized weights? What is a marginal structural model, and how are they fit? What parameters of these models are of interest? How is IP weighting used in dealing with censoring (loss-to-follow up / selection bias)? "],
["introductions-review-and-motivation.html", "Topic 1 Introductions, Review, and Motivation Learning Goals Review: Regression Models Exercises", " Topic 1 Introductions, Review, and Motivation Slides from today are available here. Learning Goals Understand the instances in which we care about causation more than association Review regression modeling and develop some ideas about its relation to causal inference goals Develop some ideas for why causal stories (i.e., expert knowledge) are crucial for causal inference goals Review: Regression Models Discuss the following questions with your group members. What does a linear regression model formula look like? If you covered logistic regression in STAT 155, what does a logistic regression model formula look like? When would you use logistic vs. linear regression? In general, how do we interpret the intercept in a regression model (both linear and logistic)? How do we interpret the other coefficients in a regression model (both linear and logistic)? How can we justify this interpretation mathematically? How might regression models be useful in understanding the causal effect of some variable on an outcome? Exercises You can download a template RMarkdown file to start from here. We will look at (simulated) data from a study that looked at the effectiveness of chemotherapy for treating colon cancer. Chemotherapy is effectively a poison that kills cells in the body that are rapidly proliferating: these cells include the cancer cells (often in a mass called a tumor) but also cells in bone marrow involved in sustaining the immune system. In this study, researchers measured the following variables: pre_tumor_size: Tumor size before the chemotherapy/placebo treatment (Small or Large). treated: ChemoYes if the patient received chemotherapy or ChemoNo if not. post_tumor_size: Tumor size 3 months after the chemotherapy/placebo treatment (Small or Large). recovery: Yes if the patient recovered from their cancer. No otherwise. You can read in the data as follows: chemo_study_data &lt;- read.csv(&quot;https://www.dropbox.com/s/vl06j75a8afw8ct/chemo_study.csv?dl=1&quot;) Exercise 1 The first step in any data analysis is to visualize your data. Let’s refamiliarize ourselves with the ggplot2 package in R. It may be helpful to have this ggplot2 cheat sheet open. Make sure to load the ggplot2 package by including library(ggplot2) at the top of your RMarkdown document. Look at the distribution of each of the 4 measured variables. What plot type is most appropriate for this type of variable? ggplot(chemo_study_data, aes(x = pre_tumor_size)) + ??? Is pre-treatment tumor size predictive of whether or not a patient received chemotherapy? Make a plot to assess this, and briefly state what conclusions can be drawn from the plot. (Hint: it will be helpful to look at the second page of the cheat sheet in the section labeled “Position Adjustments”.) ggplot(chemo_study_data, aes(x = pre_tumor_size, fill = treated)) + ??? Is pre-treatment tumor size predictive of whether or not a patient recovered? Make a plot, and briefly state your conclusions. A variable is a confounder if it is a common cause of both the treatment and outcome. This is shown in the diagram below. Given your results from parts b and c, could pre-treatment tumor size be a confounder of the relationship between chemotherapy treatment and recovery? If yes, what is the concern here? Note: the causal relationships of interest so far can be depicted in a causal diagram, shown below. An arrow between two variables indicates that one is a cause of the other (an arrow points from a cause to its effect). Exercise 2 One way to “adjust for” the influence of counfounders is to include them as predictors/explanatory variables in regression models. We can model recovery using a logistic regression model (used when the outcome variable is binary). In R, we can fit a logistic regression model using code like the following: # Fit the model and store it in the &quot;mod&quot; object mod &lt;- glm(outcome_variable ~ explanatory_variable1+explanatory_variable2, family = &quot;binomial&quot;, data = your_data) # Display model output summary(mod) Fit a logistic regression model with only treatment as a predictor. Interpret the treatment coefficient. Is this the interpretation you expected? Fit a logistic regression model with both treatment and pre-treatment tumor size as predictors. Interpret the treatment coefficient. Is this the interpretation you expected? Exercise 3 So far, we have not considered the post_tumor_size variable at all in our analyses. Let’s get some visual understanding of this variable. Make 2 plots: one showing its relationship with the treated variable and the second showing its relationship with the recovery variable. What is your intuition - should we include post_tumor_size as an explanatory variable in our logistic regression model? Why or why not? Fit the logistic regression model (mod3) with all 3 explanatory variables, and interpret the treatment coefficient. How do the results compare to mod2? The diagram that we considered at the end of Exercise 1 only included the treatment, recovery, and pre-treatment tumor size variables. Draw (on paper) an expanded causal diagram that includes post-treatment tumor size. In light of where post-treatment tumor size appears on your diagram, what does it mean to include it in the logistic regression model? The data in this investigation were simulated. That is, your instructor generated them, and thus, she actually knows the truth behind the data. The truth is that chemotherapy does have a true beneficial causal impact on recovery. Chemotherapy does increases the chance of recovery. Given this information and the insights you gained from these three exercises, try to put all of this information together. What makes sense? What remains unclear? "],
["probability-and-dags.html", "Topic 2 Probability and DAGs Learning Goals Goal 1 Lead-in to R activity: Poll Discussion R Exercises Conceptual Exercises", " Topic 2 Probability and DAGs Learning Goals Appreciate the importance of starting analysis from prior/expert knowledge Simulate data corresponding to a causal DAG Use simulations to verify the marginal/conditional independence and dependence relationships implied by DAG structures Develop notions of causal and non-causal associations in the context of graphs Goal 1 In your groups, discuss your responses to the pre-class question about the figure below (which came from this article from Nature Pediatric Research). What arrows do all of you agree on? Do you disagree on any arrows? If the question of interest is how screen time affects the risk of childhood obesity, what variables and arrows do you think are missing? If you have time left, pick your favorite example of conditional independence and conditional dependence from your answers to the pre-class questions. Lead-in to R activity: Poll Navigate to: PollEv.com/lesliemyint417 Discussion Download this Rmd file to start from. library(ggplot2) library(dplyr) An introduction to the rbinom function: # 4 different people each flip a fair coin once rbinom(4, size = 1, prob = 0.5) # 4 different people flip loaded coins # First 2 flip a coin with P(Heads) = 0.9 # Second 2 flip a coin with P(Heads) = 0.2 rbinom(4, size = 1, prob = c(0.9, 0.9, 0.2, 0.2)) # Before you run this code, what will the result be? rbinom(2, size = 1, prob = c(1, 0)) How can we simulate X -&gt; Y for binary X and Y? # set.seed() ensures reproducible random numbers set.seed(2020) # Set sample size n &lt;- 1e5 # Generate a binary variable X for all n cases X &lt;- rbinom(n, size = 1, prob = 0.5) Y &lt;- rbinom(n, size = 1, prob = 0.5) Are the X and Y we just simulated independent or dependent? Let’s make a plot to see: # We put X and Y in a dataset using data.frame() # They are turned into categorical variables using factor() sim_data &lt;- data.frame(X = factor(X), Y = factor(Y)) # Proportional bar plot ggplot(sim_data, aes(x = X, fill = Y)) + geom_bar(position = &quot;fill&quot;) How can we make Y dependent on X? # Generate probabilities that Y=1 that depend on the value of X p_Y &lt;- dplyr::case_when( X==1 ~ 0.8, X==0 ~ 0.3 ) # Simulate Y using p_Y Y &lt;- rbinom(n, size = 1, prob = p_Y) # Put X, Y, and p_Y into a dataset sim_data &lt;- data.frame(X = factor(X), Y = factor(Y), p_Y = p_Y) # Check that p_Y = 0.8 when X is 1 sim_data %&gt;% filter(X==&quot;1&quot;) # Check that p_Y = 0.3 when X is 0 sim_data %&gt;% filter(X==&quot;0&quot;) # Proportional bar plot ggplot(sim_data, aes(x = X, fill = Y)) + geom_bar(position = &quot;fill&quot;) How can we make a variable Z dependent on 2 causes: X and Y? X &lt;- rbinom(n, size = 1, prob = 0.5) Y &lt;- rbinom(n, size = 1, prob = 0.5) p_Z &lt;- dplyr::case_when( X==1 &amp; Y==1 ~ 0.8, X==0 &amp; Y==1 ~ 0.3, X==1 &amp; Y==0 ~ 0.5, X==0 &amp; Y==0 ~ 0.9 ) Z &lt;- rbinom(n, size = 1, prob = p_Z) # Put X, Y, and Z into a dataset sim_data &lt;- data.frame(X = factor(X), Y = factor(Y), Z = factor(Z)) # If we wanted to save datasets filtered on Z (Why?) sim_data_filt_z0 &lt;- sim_data %&gt;% filter(Z==&quot;0&quot;) sim_data_filt_z1 &lt;- sim_data %&gt;% filter(Z==&quot;1&quot;) R Exercises Exercise 1 Simulate data for a chain X -&gt; Y -&gt; Z where all variables are binary. Make plots to show the following properties: X and Z are marginally dependent X and Z are conditionally independent given Y Describe how your simulation would change if you wanted to check the more general property of chains that two variables are conditionally independent given any variables in between them. (You don’t actually need to implement this simulation but can if you have time.) Exercise 2 Simulate data for a fork Y &lt;- X -&gt; Z where all variables are binary. Make plots to show the following properties: Y and Z are marginally dependent Y and Z are conditionally independent given X Exercise 3 Simulate data for a collider X -&gt; Z &lt;- Y where all variables are binary. Make plots to show the following properties: X and Y are marginally independent X and Y are conditionally dependent given Z Describe how your simulation would change if you wanted to check the more general property of colliders that X and Y become dependent conditional on Z and/or any descendants of Z. (You don’t actually need to implement this simulation but can if you have time.) Conceptual Exercises Exercise 4 In the causal diagram above, let X be a treament and Y be an outcome of interest. What would you say are the “causal paths” between X and Y? What would you say are the “non-causal paths”? Thinking about the marginal and conditional independence and dependence relations we’ve discussed, how might we restrict the influence of these non-causal paths? Exercise 5 Can you come up with a general rule that tells us when two variables will be conditionally independent given another set of variables Z? (Where it is possible that Z is an empty set containing no variables.) Try out your rule on the causal diagram below. "],
["d-separation-part-1.html", "Topic 3 d-separation (Part 1) Learning Goals Discussion: d-separation Discussion: The Birth Weight Paradox", " Topic 3 d-separation (Part 1) Learning Goals Review concepts of simulating DAGs in R Understand d-separation as a general means of identifying independence/dependence in arbitrarily complex causal diagrams Apply d-separation ideas to a case study: the birth weight paradox Discussion: d-separation A path \\(p\\) is blocked by a set of nodes \\(Z\\) (which could be the empty set) if and only if at least one of the two conditions below are met. (\\(Z\\) is the set of variables being conditioned on.) \\(p\\) contains a chain of nodes \\(A \\rightarrow B \\rightarrow C\\) or a fork \\(A \\leftarrow B \\rightarrow C\\) such that the middle node \\(B\\) is in \\(Z\\). \\(p\\) contains a collider \\(A \\rightarrow B \\leftarrow C\\) such that the collision node B is not in \\(Z\\), and no descendant of \\(B\\) is in \\(Z\\). If \\(Z\\) blocks every path between two nodes \\(X\\) and \\(Y\\), then \\(X\\) and \\(Y\\) are d-separated, conditional on \\(Z\\), and are thus independent conditional on \\(Z\\). Discussion: The Birth Weight Paradox To facilitate our discussion, key pieces of information and terminology from the article are summarized below. Crude mortality rate ratio \\[\\frac{\\hbox{Infant mortality rate for maternal smokers}}{\\hbox{Infant mortality rate for maternal non-smokers}} = 1.55\\] Adjusted mortality rate ratio: same ratio but arising from a logistic regression model in which birth weight was held constant. This was 1.09. Stratum-specific mortality rate ratios In low birth weight infants: \\[\\frac{\\hbox{Infant mortality rate for maternal smokers}}{\\hbox{Infant mortality rate for maternal non-smokers}} = 0.79\\] In normal birth weight infants: \\[\\frac{\\hbox{Infant mortality rate for maternal smokers}}{\\hbox{Infant mortality rate for maternal non-smokers}} = 1.80\\] In your groups, discuss the following questions. Make sure to take good notes because the first post in your Portfolio will be a careful analysis of this paper. Throughout, remember that looking only at low birth weight infants amounts to conditioning on that variable. Using our knowledge of (in)dependence relations in DAGs, explain this quote about Figure 3.1 from the paper: “Under this scenario, the crude mortality rate ratio for smoking would be greater than 1, whereas the adjusted rate ratio and, equivalently, the stratum-specific rate ratios should be 1.” Explain why Figure 3.2 implies that the crude and adjusted mortality rate ratios would be the same. In Figure 3.5, the authors do not include an arrow from Smoking to Mortality, but they use this diagram to explain how the birth weight paradox could arise. Why is excluding this arrow a key part of their argumentation? Using Figure 3.5, explain how the paradox arises by using the ideas of d-separation. Figure 3.7 is the most realistic of the causal diagrams. Explain how the paradox arises in this setting. In Figure 3.7, would the paradox have arisen if LBW-Type A had been the selection criterion instead of LBW? Would the paradox have arisen if LBW-Type B had been the selection criterion? Let’s generalize the key findings in this paper. The term selection bias broadly describes bias in results due to the way in which study participants are selected. How did selection bias come about for the birth weight paradox? Can we generalize this occurrence in terms of more general graph properties? "],
["d-separation-part-2.html", "Topic 4 d-separation (Part 2) Learning Goals Why care? Example: Folic Acid and Birth Defects Example: Selection Bias Example: Estrogens and Uterine Cancer Principles of building causal diagrams", " Topic 4 d-separation (Part 2) Learning Goals Practice d-separation ideas with more examples Why care? In adjusting for variables in our analysis, we want to “do no harm”: Block non-causal paths that generate unwanted associations Do not accidentally create non-causal paths that generate unwanted associations Leave causal paths (chains) alone Example: Folic Acid and Birth Defects Does maternal folic acid supplementation reduce the risk of birth defects? Or could associations be due to confounding factors? What should we adjust for in our analysis? Example: Selection Bias See handout! Example: Estrogens and Uterine Cancer Does postmenopausal estrogen supplementation (hormone replacement therapy) cause uterine cancer? Consistent association between estrogen use and uterine cancer was noticed in the 1970s Two hypotheses: Estrogens do cause cancer Estrogens don’t cause cancer but lead to uterine bleeding, leading to more frequent doctor visits, leading to increased diagnosis of existing cancer Proposal for a study: restrict the study only to those with uterine bleeding and compare cancer rates in estrogen-users and non-users In this way, all participants have the same chance of being diagnosed. What could be wrong about this approach? Can we design a better study? Causal diagrams corresponding to the two hypotheses: Work through the following questions in your groups: Consider the study proposal: restrict analysis to those with uterine bleeding. Argue that under DAG 1, estrogens and diagnosed cancer will be associated. Argue that under DAG 2, estrogens and diagnosed cancer will be associated. Thus conclude that this study proposal cannot distinguish between the two competing hypotheses. Consider another study proposal: ensure that everyone is screened frequently, and we don’t restrict our analysis to only those with uterine bleeding. What arrow (in either DAG 1 or 2) can be removed as a result of this study design? In this study, say that we don’t find an association between estrogens and diagnosed cancer? What does this mean about paths from estrogens to diagnosed cancer? In this study, say that we do find an association between estrogens and diagnosed cancer? What does this mean about paths from estrogens to diagnosed cancer? Based on these investigations, make a conclusion about the quality of this study proposal as compared to the first. Principles of building causal diagrams A DAG is a causal DAG if it is common cause-complete: for any two variables in the DAG, common causes (whether measured or unmeasured) of those variables are shown. A causal DAG does NOT need to be cause-complete (infeasible due to infinite regress of causes). It should contain variables that are selected on, and subsequently common causes between those variables and existing variables. "],
["estimating-causal-effects.html", "Topic 5 Estimating causal effects Learning Goals Exercise: DAG construction Warm-up: d-separation Discussion: Estimating causal effects", " Topic 5 Estimating causal effects Learning Goals Practice constructing a causal diagram from the ground up in consultation with fellow experts Extend d-separation ideas to the estimation of causal effects Develop the idea of inverse probability of treatment weighting (IPW or IPTW) for causal effect estimation Understand how the do-operator is related to inverse probability weighting Exercise: DAG construction Research question: What is the causal effect of participating in yoga once per week for 12 weeks on resting heart rate at the end of that period? We are trying to design an observational study that could be carried out at Macalester. Recall our principles for constructing causal DAGs: A DAG is a causal DAG if it is common cause-complete: for any two variables in the DAG, common causes (whether measured or unmeasured) of those variables are shown. A causal DAG does NOT need to be cause-complete (infeasible due to infinite regress of causes). It should contain variables that are selected on, and subsequently common causes between those variables and existing variables. Reflect: Write about the process of constructing the causal diagram with your colleagues. How did your discussions flow? How did you resolve (or not) any disagreements on the structure? Were you able to decide if your diagram was good enough? If so, how? What questions or concerns do you still have about this process? Further reading: Chapter 9 of our WHATIF book (see References) introduces the consideration of measurement error. We won’t talk about measurement error in this course but you are welcome to read about these ideas on your own. Chapters 6, 7, and 8 talk about causal diagrams, confounding, and selection bias. This another resource to complement PRIMER. Warm-up: d-separation Navigate to: PollEv.com/lesliemyint417 Slides of the causal diagrams (with solutions) are available here. Discussion: Estimating causal effects In adjusting for variables in our analysis, we want to “do no harm”: Block non-causal paths that generate unwanted associations Do not accidentally create non-causal paths that generate unwanted associations Leave causal paths (chains) alone This was actually the rationale behind the backdoor criterion. (We’ll get back to this soon.) The do-operator One notion of causation is that of intervention: setting a variable’s value There is a difference between \\(P(Y \\mid A = a)\\) and \\(P(Y \\mid \\hbox{do}(A = a))\\). \\(P(Y \\mid A = a)\\) is an observational probability \\(P(Y \\mid \\hbox{do}(A = a))\\) is an intervention probability When we intervene on \\(A\\), this amounts to removing all arrows into \\(A\\). The do-operator allows us to graphically simulate interventions. In the world that was intervened on (manipulated), what do relationships between variables look like? Rules of probability combined with a set of graph rules (called the do-calculus) allow us to relate the relationships in the manipulated graph to relationships that we observe in the real world. \\[ \\hbox{Average causal effect} = P(Y = y \\mid \\hbox{do}(A = 1)) - P(Y = y \\mid \\hbox{do}(A = 0)) \\] \\(Y\\) is the outcome and \\(A\\) is the treatment (action) variable Taste of do-calculus next week. For now, let’s approach effect estimation from a different angle: The mathematical expressions in PRIMER for \\(P(y \\mid \\hbox{do}(a))\\) had something in common –&gt; let’s develop this idea and relate to something familiar: d-separation Worksheet: developing ideas Worksheet (with solutions) available here Notes: deriving inverse probability weighting If treatment \\(A\\) and outcome \\(Y\\) are d-separated given \\(Z\\) under the null (under the null hypothesis of no causal effect), then there are no open “spurious” paths generating unwanted associations between \\(A\\) and \\(Y\\). No open backdoor paths (paths with arrows into \\(A\\)): these generate confounding. No paths with collision nodes or descendants of collision nodes that are conditioned on: this opens paths that would otherwise be naturally blocked by the collision nodes. Then the outcomes of the treated and untreated are “comparable”. No open spurious paths. If the outcomes of the treated and untreated are “comparable”, then… We can upweight those treated to “create” a population where everyone was treated –&gt; look at outcome distributions in this population (e.g., \\(P(Y = 1)\\)). These weights are the inverse of \\(P(A = 1\\mid Z)\\). We can upweight those not treated to “create” a population where everyone was not treated –&gt; look at outcome distributions in this population (e.g., \\(P(Y = 1)\\)). These weights are the inverse of \\(P(A = 0\\mid Z)\\). These outcome distributions are actually interpreted as: All treated: \\(P(Y = 1 \\mid \\hbox{do}(A = 1))\\) All not treated: \\(P(Y = 1 \\mid \\hbox{do}(A = 0))\\) Note: we have appealed to what it conceptually means to do/intervene. We haven’t done any “graph surgery”. \\[ \\hbox{Average causal effect} = \\hbox{ACE} = P(Y = 1 \\mid \\hbox{do}(A = 1)) - P(Y = 1 \\mid \\hbox{do}(A = 0)) \\] If ACE = 0.1, interpreted as: The probability of recovery (\\(Y = 1\\)) is 10% higher if we treat everyone, as compared to if we treat no one. The individual “do” probabilities are actually weighted averages of the outcome variable: \\[ P(Y = 1 \\mid \\hbox{do}(A = a)) = \\frac{\\sum_i w_i y_i}{\\sum_i w_i} \\] \\(w_i\\) is the appropriate weight for case \\(i\\) \\(y_i\\) is the outcome for case \\(i\\) The sum is over all treated for \\(a = 1\\) and over all untreated for \\(a = 0\\). Punchline: If treatment \\(A\\) and outcome \\(Y\\) are d-separated given \\(Z\\) under the null, we can estimate desired “do” probabilities with \\[ P(Y = 1 \\mid \\hbox{do}(A = a)) = \\frac{\\sum_i w_i y_i}{\\sum_i w_i} \\] where the weights \\(w_i\\) are the inverse propensity scores: \\(w_i = 1/P(A = 1 \\mid Z)\\) if \\(a = 1\\) \\(w_i = 1/P(A = 0 \\mid Z)\\) if \\(a = 0\\) When \\(Z\\) contains many variables, we can’t tabulate as we did by hand (too many combinations of predictor levels relative to our sample size). Need to model treatment as a function of the variables in \\(Z\\). Logistic regression Other techniques from Statistical Machine Learning Exercise: Simulation planning Goal: Plan (then implement) a simulation that shows that inverse probability of treatment weighting (IPTW) to estimate average causal effects gives the same results as using the do-operator. This will be done in the context of the DAG below. Plan: As you go through this planning, think about what code you would have to write (in broad terms) and the order in which you would have to run those commands. For this exercise, don’t look at the code below. We’ll get to it next. Phase 1: How would you simulate the DAG below? (All variables binary.) How would you simulate new versions of Y under the manipulated graphs resulting from do(A = 1) and do(A = 0)? How would you compute the average causal effect from do-ing? Phase 2: How would you estimate the propensity score for each individual? How would you estimate P(Y = 1 | do(A = 1)) and P(Y = 1 | do(A = 0)) using those estimated propensity scores? After your planning phase, step through the code in the section below, and make sure that you understand what each line is doing. Clarify with the instructor as needed. Simulation example A template Rmd is available here. Task 1: What is the point of this simulation exercise? What are we trying to show? Clearly explain how we are approaching causal effect estimation from two seemingly different viewpoints. Task 2: Explain in detail all steps taken in this code. Do this by breaking the code into smaller code chunks and adding text in between. library(dplyr) Phase 1: set.seed(22) n &lt;- 1e6 Z &lt;- rbinom(n, size = 1, prob = 0.5) p_A &lt;- dplyr::case_when( Z==1 ~ 0.8, Z==0 ~ 0.3 ) A &lt;- rbinom(n, size = 1, prob = p_A) p_Y &lt;- dplyr::case_when( Z==1 &amp; A==1 ~ 0.3, Z==1 &amp; A==0 ~ 0.6, Z==0 &amp; A==1 ~ 0.9, Z==0 &amp; A==0 ~ 0.2 ) Y &lt;- rbinom(n, size = 1, prob = p_Y) A_do_1 &lt;- rep(1, n) A_do_0 &lt;- rep(0, n) p_Y_Ado1 &lt;- dplyr::case_when( Z==1 &amp; A_do_1==1 ~ 0.3, Z==1 &amp; A_do_1==0 ~ 0.6, Z==0 &amp; A_do_1==1 ~ 0.9, Z==0 &amp; A_do_1==0 ~ 0.2 ) Y_Ado1 &lt;- rbinom(n, size = 1, prob = p_Y_Ado1) p_Y_Ado0 &lt;- dplyr::case_when( Z==1 &amp; A_do_0==1 ~ 0.3, Z==1 &amp; A_do_0==0 ~ 0.6, Z==0 &amp; A_do_0==1 ~ 0.9, Z==0 &amp; A_do_0==0 ~ 0.2 ) Y_Ado0 &lt;- rbinom(n, size = 1, prob = p_Y_Ado0) sim_data &lt;- data.frame(Z, A, Y, Y_Ado1, Y_Ado0) sum(sim_data$Y_Ado1==1)/n sum(sim_data$Y_Ado0==1)/n (sum(sim_data$Y_Ado1==1)/n)-(sum(sim_data$Y_Ado0==1)/n) Phase 2: # Fit a logistic regression model to estimate propensity scores ps_mod &lt;- glm(A ~ Z, data = sim_data, family = &quot;binomial&quot;) # Get the actual propensity scores # predict(..., type = &quot;response&quot;) gives the predicted probabilities from logistic regression # What computations are going on behind the scenes? sim_data$PS &lt;- dplyr::case_when( A==1 ~ predict(ps_mod, type = &quot;response&quot;), A==0 ~ 1-predict(ps_mod, type = &quot;response&quot;) ) # Form inverse probability weights sim_data$weight &lt;- 1/sim_data$PS # Use the IP weights to estimate: # (1) the average outcome if all people were treated # (2) the average outcome if all people were untreated # group_by() forms groups according to the given variable # summarize() computes a summary measure for those groups results &lt;- sim_data %&gt;% group_by(A) %&gt;% summarize(Y_po_estim = sum(Y*weight)/sum(weight)) # Display estimates (1) and (2) results # Compute the estimated average causal effect (ACE) # How does it compare to the truth from &quot;do&quot;ing? diff(results$Y_po_estim) On your own Adapt the simulation to a situation with 2 confounders Z and W as in the DAG below: Note: To simulate dependence on 3 or more variables (e.g., A depends on B, C, and D), an easier approach is to do as below: p_B &lt;- dplyr::case_when( B==1 ~ 0.8, B==0 ~ 0.4 ) p_C &lt;- dplyr::case_when( C==1 ~ 0.9, C==0 ~ 0.5 ) p_D &lt;- dplyr::case_when( D==1 ~ 0.7, D==0 ~ 0.1 ) p_A &lt;- p_B*p_C*p_D If ever D is equal to 1 for all cases, p_A can be updated as: p_A_D1 &lt;- p_B*p_C*0.7 If ever D is equal to 0 for all cases, p_A can be updated as: p_A_D1 &lt;- p_B*p_C*0.1 Questions and Tasks: When you generate \\(A\\), use the following probabilities: p_A &lt;- dplyr::case_when( Z==1 &amp; W==1 ~ 0.3, Z==1 &amp; W==0 ~ 0.6, Z==0 &amp; W==1 ~ 0.9, Z==0 &amp; W==0 ~ 0.2 ) How close are your estimates of the ACE from IP weighting and from graph surgery? Take a careful look at the probabilities used to generate the treatment \\(A\\), and re-examine the form of your propensity score model. Thinking about what the coefficients mean in your propensity score (PS) model, what would you need to do to improve your propensity score model? Fit this new PS model as ps_mod2. Add a second PS variable PS2, and create a corresponding weight2 variable. Store the results from both PS models with something similar to below, Display the estimated ACE resulting from both models. results &lt;- sim_data %&gt;% group_by(A) %&gt;% summarize( Y_po_estim1 = sum(Y*weight1)/sum(weight1), Y_po_estim2 = sum(Y*weight2)/sum(weight2) ) Repeat this simulation using numbers for p_A that make the simpler PS model valid. As before, show the results of both the simpler and more complex PS model. "],
["homework-1.html", "Homework 1 Conceptual Exercises Simulation Exercises Portfolio", " Homework 1 Due Thursday, February 13 in class Conceptual Exercises These exercises can be turned in on paper in class. Exercise 1 We have looked at 3 DAG structures (chains, forks, and colliders) and claimed that they are the building blocks of all DAGs. Is this true? We will verify this premise in this exercise. Let’s start by considering all possible directed (not necessarily acyclic) graphs with 3 variables. (Three is the smallest number of nodes where any interesting structures can arise.) There are 27 of these graphs. Draw all of these graphs with the aid of the expand.grid() function in R. First, look up the documentation for this function. Second, run the command below to get a sense for how the function can help you. For this part, display the 27 graphs, and provide a brief explanation of how expand.grid() helped. expand.grid( X_to_Y = c(&quot;-&gt;&quot;, &quot;&lt;-&quot;, &quot;absent&quot;), Y_to_Z = c(&quot;-&gt;&quot;, &quot;&lt;-&quot;, &quot;absent&quot;), X_to_Z = c(&quot;-&gt;&quot;, &quot;&lt;-&quot;, &quot;absent&quot;) ) From your list of graphs, indicate which graphs can be eliminated because they are cyclic. From your list of graphs, indicate which graphs can be eliminated because they are useless causal models. In your list of graphs, some graphs are essentially the same. Group these together, and draw one representative graph from each group. Briefly form a conclusion based on these investigations. Exercise 2 PRIMER, Study question 2.3.1: Parts (c), (e), and (f). For parts (e) and (f), explain your thinking. Exercise 3 PRIMER, Study question 2.4.1: Parts (a), (b), and (c). For part (b), only d-separate pairs of non-adjacent measured variables. Simulation Exercises On Moodle, turn these exercises in by submitting both your Rmd file and the knitted HTML. For these exercises, ensure that your plots are well-labeled. Add the following to the ends of your plots to label your plots accurately: + labs(x = &quot;x axis label&quot;, y = &quot;y axis label&quot;, title = &quot;overall plot title&quot;) A refresher on facet_grid() that may be useful: To form panels across columns by variable Y: + facet_grid(~ Y) To form a grid of panels where rows correspond to X and columns to Y: + facet_grid(X ~ Y) To form a grid of panels where rows correspond to X and columns to Y and Z: + facet_grid(X ~ Y+Z) In case you’re curious about how to change the labeling of facet titles, see here. (Optional) You may or may not find it helpful/enjoyable to use the gridExtra package for arranging your plots. Example use case: library(gridExtra) p1 &lt;- ggplot(...) # Plot 1 p2 &lt;- ggplot(...) # Plot 2 p3 &lt;- ggplot(...) # Plot 3 p4 &lt;- ggplot(...) # Plot 4 # To arrange the 4 plots in a 2x2 grid: grid.arrange(p1, p2, p3, p4, ncol = 2, nrow = 2) If you look at your knitted HTML and think that your plots are too small, you can change the beginning of your code chunks to the following (playing with the numbers as needed): ```{r fig.width=12, fig.height=5} Exercise 4 Simulate data for a chain X -&gt; Y -&gt; Z where all variables are binary. Make plots to show the following properties: X and Z are marginally dependent X and Z are conditionally independent given Y Clearly explain how the plots show the dependence or independence. When you use dplyr::case_when() to generate probabilities that depend on another single variable, will any set of numbers work? Explain. Give an example of a set of numbers that would not generate the desired results. Exercise 5 Simulate data for a fork Y &lt;- X -&gt; Z where all variables are binary. Make plots to show the following properties: Y and Z are marginally dependent Y and Z are conditionally independent given X Exercise 6 Simulate data for a collider X -&gt; Z &lt;- Y where all variables are binary. Make plots to show the following properties: X and Y are marginally independent X and Y are conditionally dependent given Z When you use dplyr::case_when() to generate probabilities that depend on two variables, will any set of numbers work? Explain. Give an example of a set of numbers that would not generate the desired results. Exercise 7 Simulate data corresponding to the causal diagram in Figure 2.8 of PRIMER. Ignore the U variables (error terms) in the diagram, and treat all variables (T, Z, W, X, Y, and U) as binary. Make plots to show the following properties, and explain why they hold using the rules of d-separation: Z and Y are marginally dependent Z and Y are conditionally independent given T Z and Y are conditionally dependent given T and W Z and Y are conditionally independent given T, W, and X Portfolio Work on a draft post for required topic #1 (the birth weight paradox). "],
["homework-2.html", "Homework 2 In-class activities: Estimating causal effects In-class activities: IP weighting in practice", " Homework 2 Due Tuesday, February 25 at midnight on Moodle In-class activities: Estimating causal effects Turn in required parts of the class exercises from Topic 5: Estimating causal effects. These parts include: Simulation example: Tasks 1 and 2 On your own: Questions and Tasks 1 to 5 In-class activities: IP weighting in practice Turn in all class exercises from Topic 6: IP weighting in practice "],
["portfolio-1.html", "Portfolio Required Topics Iterative Progress Building a Personal Website", " Portfolio Your portfolio is meant to be a well-written collection of documents about course topics. The hope is that this collection is a useful reference for yourself years down the line, but potentially it will be helpful for others who may happen across your material. Because of these goals, your portfolio will be a collection of blog posts. If you are keen on building your own website, you could publish these posts there as a part of building up an online presence. This is certainly not a requirement for class though. How you organize and structure your posts is up to you, but they need to address the topics below. Required Topics (This list will grow as the semester progresses.) An analysis of the article The Birth Weight “Paradox” Uncovered? at the level of detail of our in-class discussion. The post does not have to answer the exact same discussion questions posed in class. The post should explain the paradox and what the authors did to investigate it. This should include a discussion of how they proceeded through the various causal diagrams and why some were eliminated. The post should explain how the authors resolved the paradox in the most realistic causal diagrams. The post should conclude with general lessons learned from this example. Iterative Progress You will work on these posts iteratively throughout the semester. The homework assignments will give deadlines for when a rough draft is due. Although writing rough drafts will be part of your homework duties, the drafts will not be part of your homework grade. You will only receive qualitative feedback from me on your drafts. This will be the process for writing and feedback for the semester: Create one (and only one) new Google Doc. This will be where all of your drafts go. Enable link sharing so that those with the link can edit. Submit the link on Moodle &gt; Homework &gt; Portfolio Google Doc Link. Start writing! In the days after draft due dates, I will be reading your drafts and giving feedback by a fixed time. You are welcome to revise based on my feedback as many times as you want. When you would like another round of feedback, add a comment to the relevant section and tag me in it to bring it to my attention. (Type a “+” in the comment box followed by my email address.) Building a Personal Website If you are curious about building your own website, read on! First check out the instructor’s website. If you like the layout and want to try making a website using R (the blogdown package), read her blog post about setting up her website. "]
]
